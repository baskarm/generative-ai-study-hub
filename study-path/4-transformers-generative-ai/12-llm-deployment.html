
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://baskarm.github.io/generative-ai-study-hub/study-path/4-transformers-generative-ai/12-llm-deployment.html">
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.15">
    
    
      
        <title>12 llm deployment - Generative AI Study Hub</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7CFira+Code:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Inter";--md-code-font:"Fira Code"}</style>
      
    
    
      <link rel="stylesheet" href="../../styles/logo.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="deep-purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#quick-navigation" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../index.html" title="Generative AI Study Hub" class="md-header__button md-logo" aria-label="Generative AI Study Hub" data-md-component="logo">
      
  <img src="../../images/adhana.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Generative AI Study Hub
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              12 llm deployment
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="deep-purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="deep-purple" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../index.html" class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../1-python/index.html" class="md-tabs__link">
        
  
  
    
  
  Python

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../2-statistics/index.html" class="md-tabs__link">
        
  
  
    
  
  Statistics

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../3-datascience-machine-learning/index.html" class="md-tabs__link">
        
  
  
    
  
  DS & ML

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="index.html" class="md-tabs__link">
        
  
  
    
  
  Transformers & Gen AI

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../5-rag-langchain/index.html" class="md-tabs__link">
        
  
  
    
  
  RAG + LangChain

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../6-llmops/index.html" class="md-tabs__link">
        
  
  
    
  
  LLM Ops

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../7-ai-eval-engineering/index.html" class="md-tabs__link">
        
  
  
    
  
  AI Evaluation

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../reference-hub/index.html" class="md-tabs__link">
          
  
  
    
  
  Reference Hub

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../index.html" title="Generative AI Study Hub" class="md-nav__button md-logo" aria-label="Generative AI Study Hub" data-md-component="logo">
      
  <img src="../../images/adhana.png" alt="logo">

    </a>
    Generative AI Study Hub
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../1-python/index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../2-statistics/index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Statistics
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../3-datascience-machine-learning/index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DS & ML
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transformers & Gen AI
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../5-rag-langchain/index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RAG + LangChain
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../6-llmops/index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    LLM Ops
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../7-ai-eval-engineering/index.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AI Evaluation
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../reference-hub/index.html" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Reference Hub
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_9" id="__nav_9_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            Reference Hub
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9_2" >
        
          
          <label class="md-nav__link" for="__nav_9_2" id="__nav_9_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Foundation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_9_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9_2">
            <span class="md-nav__icon md-icon"></span>
            Foundation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/foundation/nlp-overview.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    NLP Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/foundation/transformers.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transformers
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/foundation/models.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Models
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9_3" >
        
          
          <label class="md-nav__link" for="__nav_9_3" id="__nav_9_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Practice
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_9_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9_3">
            <span class="md-nav__icon md-icon"></span>
            Practice
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/practice/tokenization.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tokenization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/practice/embeddings.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Embeddings
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/practice/fine-tuning.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Fine Tuning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/practice/efficiency.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Efficiency
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9_4" >
        
          
          <label class="md-nav__link" for="__nav_9_4" id="__nav_9_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Applications
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_9_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9_4">
            <span class="md-nav__icon md-icon"></span>
            Applications
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/applications/semantic-search.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Semantic Search
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/applications/qa-over-docs.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    QA from Docs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/applications/instruction-tuning.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Instruction Tuning
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9_5" >
        
          
          <label class="md-nav__link" for="__nav_9_5" id="__nav_9_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    LLMs
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_9_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9_5">
            <span class="md-nav__icon md-icon"></span>
            LLMs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/llms/intro.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/llms/rlhf.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RLHF
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/llms/scaling.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Scaling
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9_6" >
        
          
          <label class="md-nav__link" for="__nav_9_6" id="__nav_9_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Knowledge
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_9_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9_6">
            <span class="md-nav__icon md-icon"></span>
            Knowledge
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/knowledge/prompt-engineering.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Prompt Engineering
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/knowledge/huggingface.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hugging Face
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/knowledge/research.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Research Notes
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/knowledge/tools.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tools & Libraries
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference-hub/knowledge/learning-links.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Learning Links
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



  <h1>12 llm deployment</h1>

<h2 id="quick-navigation">Quick Navigation</h2>
<ul>
<li><a href="#introductory-concepts-for-scale-training">Introductory Concepts for Scale Training</a></li>
<li><a href="#understanding-deepspeed-theoretically">Understanding DeepSpeed Theoretically</a></li>
<li><a href="#implementing-deepspeed-practically">Implementing DeepSpeed Practically</a></li>
<li><a href="#fully-sharded-data-parallel-fsdp-theoretical-insights">Fully Sharded Data Parallel (FSDP) Theoretical Insights</a></li>
<li><a href="#applying-fsdp-in-practice">Applying FSDP in Practice</a></li>
<li><a href="#course-conclusion-and-future-directions">Course Conclusion and Future Directions</a></li>
<li><a href="#practice-test-2-llm-mastery">Practice Test 2: LLM Mastery</a></li>
</ul>
<hr />
<h2 id="introductory-concepts-for-scale-training">Introductory Concepts for Scale Training</h2>
<h2 id="quick-navigation_1">Quick Navigation</h2>
<ul>
<li><a href="#introduction-to-multi-gpu-scaling">Introduction to Multi-GPU Scaling</a></li>
<li><a href="#why-scaling-is-necessary">Why Scaling is Necessary</a></li>
<li><a href="#strategic-goals-of-scaling">Strategic Goals of Scaling</a></li>
<li><a href="#from-optimization-to-hardware-expansion">From Optimization to Hardware Expansion</a></li>
<li><a href="#preview-of-scaling-frameworks">Preview of Scaling Frameworks</a></li>
<li><a href="#references--further-reading">References &amp; Further Reading</a></li>
</ul>
<hr />
<h2 id="introduction-to-multi-gpu-scaling">Introduction to Multi-GPU Scaling</h2>
<p>In this final section, we shift our focus from single-machine optimization to <strong>scaling across multiple GPUs or nodes</strong>. While techniques such as quantization, LoRA, and flash attention helped maximize limited resources, we now explore strategies that increase total computational power by adding hardware.</p>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="why-scaling-is-necessary">Why Scaling is Necessary</h2>
<p>Scaling allows us to break free from the physical constraints of a single GPU. There are two primary motivations for doing so:</p>
<ul>
<li><strong>Training larger models</strong>: Eventually, no matter how optimized, a model won't fit into GPU memory.</li>
<li><strong>Faster training</strong>: Even for smaller models, scaling enables faster iteration and experimentation by parallelizing the training workload.</li>
</ul>
<p>State-of-the-art LLMs (like GPT-4, Gemini, Claude) are trained across <strong>hundreds to thousands of GPUs simultaneously</strong>.</p>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="strategic-goals-of-scaling">Strategic Goals of Scaling</h2>
<p>Scaling isn’t only about “going bigger.” It’s also about going <strong>faster</strong>, or both.</p>
<ul>
<li><strong>Goal 1</strong>: Train <strong>larger models</strong> that wouldn't fit in memory otherwise.</li>
<li><strong>Goal 2</strong>: Train <strong>faster</strong>, reducing the time per epoch or iteration.</li>
<li><strong>Hybrid Goal</strong>: Train <strong>moderately larger models faster</strong>, using distributed compute efficiently.</li>
</ul>
<p>🔁 The balance between size, speed, and hardware availability guides the scaling strategy.</p>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="from-optimization-to-hardware-expansion">From Optimization to Hardware Expansion</h2>
<p>Previously, we relied on:
- 4-bit quantization
- Flash Attention
- QLoRA
- Efficient batch and sequence tuning</p>
<p>These <strong>maximize utilization of a single GPU</strong>, often squeezing 27B+ parameter models into 24GB cards.</p>
<p>Now, we explore <strong>hardware scaling</strong>, where:
- Multiple GPUs share memory and gradient updates
- Compute is parallelized for greater throughput</p>
<p>This introduces complexity in terms of synchronization, communication overhead, and model sharding, but unlocks <strong>next-level capabilities</strong>.</p>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="preview-of-scaling-frameworks">Preview of Scaling Frameworks</h2>
<p>We will explore and compare two major frameworks for distributed LLM training:</p>
<ol>
<li><strong>DeepSpeed</strong> (by Microsoft):</li>
<li>Efficient training of very large models</li>
<li>
<p>Includes ZeRO optimizer and communication-efficient primitives</p>
</li>
<li>
<p><strong>Fully Sharded Data Parallel (FSDP)</strong> (by PyTorch):</p>
</li>
<li>Parameter, gradient, and optimizer sharding</li>
<li>Native PyTorch integration with strong memory savings</li>
</ol>
<p>Both frameworks enable:
- Multi-GPU training
- Reduced memory load per device
- High-speed training with scalable architecture</p>
<p>Next, we begin hands-on work with <strong>DeepSpeed</strong>.</p>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="references-further-reading">References &amp; Further Reading</h2>
<ul>
<li><a href="https://github.com/microsoft/DeepSpeed">DeepSpeed GitHub</a></li>
<li><a href="https://www.deepspeed.ai/">DeepSpeed Docs</a></li>
<li><a href="https://pytorch.org/docs/stable/fsdp.html">FSDP Documentation – PyTorch</a></li>
<li><a href="https://arxiv.org/abs/1910.02054">ZeRO Redundancy Optimizer (ZeRO)</a></li>
<li><a href="https://arxiv.org/abs/2001.08361">Scaling Laws for Neural Language Models</a></li>
<li><a href="https://arxiv.org/abs/2205.14135">Accelerating Training with Flash Attention</a></li>
<li><a href="https://arxiv.org/abs/2305.14314">LoRA and QLoRA Papers</a></li>
</ul>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="understanding-deepspeed-theoretically">Understanding DeepSpeed Theoretically</h2>
<h2 id="quick-navigation_2">Quick Navigation</h2>
<ul>
<li><a href="#what-is-deepspeed">What is DeepSpeed</a></li>
<li><a href="#why-use-deepspeed">Why Use DeepSpeed</a></li>
<li><a href="#ZeRO-optimization-stages">ZeRO Optimization Stages</a></li>
<li><a href="#comparison-of-ZeRO-stages">Comparison of ZeRO Stages</a></li>
<li><a href="#when-to-use-each-stage">When to Use Each Stage</a></li>
<li><a href="#references--further-reading">References &amp; Further Reading</a></li>
</ul>
<hr />
<h2 id="what-is-deepspeed">What is DeepSpeed</h2>
<p><strong>DeepSpeed</strong> is an open-source deep learning optimization library developed by Microsoft. It is designed to:
- Speed up training
- Enable training of very large models
- Efficiently utilize multiple GPUs through advanced parallelization strategies</p>
<p>Key features include:
- Model parallelism
- Gradient and parameter partitioning
- Memory and compute optimizations</p>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="why-use-deepspeed">Why Use DeepSpeed</h2>
<p>DeepSpeed is built for high-scale model training. It helps:
- Distribute models across multiple GPUs
- Lower memory footprint per GPU
- Improve throughput in both research and production-scale workloads</p>
<p>It is ideal for:
- Training large LLMs efficiently
- Use cases where hardware and time are critical resources</p>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="zero-optimization-stages">ZeRO Optimization Stages</h2>
<p>The core innovation of DeepSpeed is the <strong>ZeRO (ZeRO Redundancy Optimizer)</strong> framework, which is broken down into three stages:</p>
<h3 id="stage-1-zero-1">Stage 1: ZeRO-1</h3>
<ul>
<li>Partitions optimizer states across GPUs</li>
<li>Provides slight memory savings</li>
<li>Fastest among all stages</li>
</ul>
<h3 id="stage-2-zero-2">Stage 2: ZeRO-2</h3>
<ul>
<li>Partitions both optimizer states and gradients</li>
<li>Reduces memory load further</li>
<li>Slower than ZeRO-1 due to added overhead</li>
</ul>
<h3 id="stage-3-zero-3">Stage 3: ZeRO-3</h3>
<ul>
<li>Partitions optimizer states, gradients, and model parameters</li>
<li>Offers maximum memory savings</li>
<li>Slowest stage due to high communication overhead</li>
</ul>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="comparison-of-zero-stages">Comparison of ZeRO Stages</h2>
<table>
<thead>
<tr>
<th>Stage</th>
<th>Speed</th>
<th>Memory Efficiency</th>
<th>Components Partitioned</th>
</tr>
</thead>
<tbody>
<tr>
<td>ZeRO-1</td>
<td>🟢 Fastest</td>
<td>🔴 Lowest</td>
<td>Optimizer states</td>
</tr>
<tr>
<td>ZeRO-2</td>
<td>🟡 Moderate</td>
<td>🟡 Moderate</td>
<td>Optimizer states + Gradients</td>
</tr>
<tr>
<td>ZeRO-3</td>
<td>🔴 Slowest</td>
<td>🟢 Highest</td>
<td>Optimizer states + Gradients + Model Parameters</td>
</tr>
</tbody>
</table>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="when-to-use-each-stage">When to Use Each Stage</h2>
<ul>
<li><strong>ZeRO-1</strong>: Use when training time is the main constraint and memory is not a major issue.</li>
<li><strong>ZeRO-2</strong>: Use when training moderately large models with balanced speed/memory tradeoff.</li>
<li><strong>ZeRO-3</strong>: Use when maximum model size is required, even at the cost of training speed.</li>
</ul>
<p>These stages give developers flexibility to choose based on their needs and available hardware.</p>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="references-further-reading_1">References &amp; Further Reading</h2>
<ul>
<li><a href="https://github.com/deepspeedai/DeepSpeed">DeepSpeed GitHub</a></li>
<li><a href="https://arxiv.org/abs/1910.02054">ZeRO Paper – Optimizer Redundancy Elimination</a></li>
<li><a href="https://www.deepspeed.ai/">DeepSpeed Documentation</a></li>
<li><a href="https://pytorch.org/docs/stable/fsdp.html">PyTorch FSDP Docs (for comparison)</a></li>
<li><a href="https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-and-inference/">Efficient Training Techniques by Microsoft</a></li>
</ul>
<p><a href="#quick-navigation">Back to Top</a></p>
<p>--</p>
<hr />
<h2 id="implementing-deepspeed-practically">Implementing DeepSpeed Practically</h2>
<h2 id="quick-navigation_3">Quick Navigation</h2>
<ul>
<li><a href="#setting-up-the-environment">Setting Up the Environment</a></li>
<li><a href="#training-llama-3-8b-without-deepspeed">Training LLaMA 3-8B Without DeepSpeed</a></li>
<li><a href="#enabling-deepspeed-integration">Enabling DeepSpeed Integration</a></li>
<li><a href="#running-training-on-multiple-gpus">Running Training on Multiple GPUs</a></li>
<li><a href="#ZeRO-1-json-configuration">ZeRO-1 JSON Configuration</a></li>
<li><a href="#deepspeed-training-yaml-configuration">DeepSpeed Training YAML Configuration</a></li>
<li><a href="#colab-notebook">Colab Notebook</a></li>
<li><a href="#references--further-reading">References &amp; Further Reading</a></li>
</ul>
<hr />
<h2 id="setting-up-the-environment">Setting Up the Environment</h2>
<p>In this lesson, we apply DeepSpeed practically to train the <code>Meta-LLaMA-3.1-8B-Instruct</code> model using two GPUs.<br />
The goal is to optimize <strong>training speed</strong> rather than memory efficiency.</p>
<ul>
<li>Starting from an Axolotl-based setup</li>
<li>Using the SQuAD dataset</li>
<li>Measuring single-GPU vs. multi-GPU time comparisons</li>
</ul>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="training-llama-3-8b-without-deepspeed">Training LLaMA 3-8B Without DeepSpeed</h2>
<p>Initial benchmark:
- Run on <strong>1 GPU</strong>
- Training time: ~1 hour 40 minutes
- CUDA visibility set to restrict GPU usage
- Dataset: <code>squad-for-llms</code>
- Model: <code>Meta-LLaMA-3.1-8B-Instruct</code></p>
<p>This baseline helps quantify the gains from enabling DeepSpeed later.</p>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="enabling-deepspeed-integration">Enabling DeepSpeed Integration</h2>
<p>DeepSpeed support is built into Axolotl. It provides default JSON configs for:
- ZeRO-1
- ZeRO-2
- ZeRO-3</p>
<h3 id="how-to-enable">How to Enable:</h3>
<ol>
<li>Copy the desired config (e.g., <code>ZeRO1.json</code>) from <a href="https://github.com/axolotl-ai-cloud/axolotl/tree/main/deepspeed_configs">Axolotl DeepSpeed Configs</a></li>
<li>Set it in your training command via <code>deepspeed</code> parameter</li>
<li>Launch Axolotl with multiple GPUs (remove <code>CUDA_VISIBLE_DEVICES</code> restriction)</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="m">0</span>,1<span class="w"> </span>accelerate<span class="w"> </span>launch<span class="w"> </span>train.py<span class="w"> </span>--deepspeed<span class="o">=</span>ZeRO1.json<span class="w"> </span>...
</code></pre></div>
<p>🟢 Outcome: Multi-GPU training initiated with backend set to DeepSpeed</p>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="running-training-on-multiple-gpus">Running Training on Multiple GPUs</h2>
<ul>
<li>Training is re-launched using both GPUs</li>
<li>ZeRO-1 stage selected (focused on speed, not memory saving)</li>
<li>Each GPU runs a <strong>full copy</strong> of the model</li>
<li>Results:</li>
<li>New training time: ~1 hour</li>
<li>~40% speed improvement with 2 GPUs</li>
</ul>
<p>🔁 Although not linear, the scaling is significant and useful in production and experimentation workflows.</p>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="zero-1-json-configuration">ZeRO-1 JSON Configuration</h2>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;ZeRO_optimization&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;stage&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;overlap_comm&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;bf16&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;fp16&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;auto_cast&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;initial_scale_power&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">32</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;loss_scale_window&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1000</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;hysteresis&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;min_loss_scale&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;gradient_accumulation_steps&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;gradient_clipping&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;train_batch_size&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;train_micro_batch_size_per_gpu&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;wall_clock_breakdown&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span>
<span class="p">}</span>
</code></pre></div>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="deepspeed-training-yaml-configuration">DeepSpeed Training YAML Configuration</h2>
<div class="highlight"><pre><span></span><code><span class="nt">base_model</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">unsloth/Meta-Llama-3.1-8B-Instruct</span>

<span class="nt">datasets</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">TheFuzzyScientist/squad-for-llms</span>
<span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span>
<span class="w">      </span><span class="nt">system_prompt</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Read</span><span class="nv"> </span><span class="s">the</span><span class="nv"> </span><span class="s">following</span><span class="nv"> </span><span class="s">context</span><span class="nv"> </span><span class="s">and</span><span class="nv"> </span><span class="s">concisely</span><span class="nv"> </span><span class="s">answer</span><span class="nv"> </span><span class="s">my</span><span class="nv"> </span><span class="s">question.&quot;</span>
<span class="w">      </span><span class="nt">field_system</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">system</span>
<span class="w">      </span><span class="nt">field_instruction</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">question</span>
<span class="w">      </span><span class="nt">field_input</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">context</span>
<span class="w">      </span><span class="nt">field_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">output</span>
<span class="w">      </span><span class="nt">format</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&lt;|user|&gt;\n</span><span class="nv"> </span><span class="s">{input}</span><span class="nv"> </span><span class="s">{instruction}</span><span class="nv"> </span><span class="s">&lt;/s&gt;\n&lt;|assistant|&gt;&quot;</span>
<span class="w">      </span><span class="nt">no_input_format</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;&lt;|user|&gt;</span><span class="nv"> </span><span class="s">{instruction}</span><span class="nv"> </span><span class="s">&lt;/s&gt;\n&lt;|assistant|&gt;&quot;</span>

<span class="nt">output_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./models/Llama3_squad</span>

<span class="nt">sequence_length</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2048</span>
<span class="nt">bf16</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">auto</span>
<span class="nt">tf32</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">micro_batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="nt">num_epochs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="nt">optimizer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">adamw_bnb_8bit</span>
<span class="nt">learning_rate</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.0002</span>
<span class="nt">logging_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>

<span class="nt">adapter</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">lora</span>
<span class="nt">lora_r</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">32</span>
<span class="nt">lora_alpha</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">16</span>
<span class="nt">lora_dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.05</span>
<span class="nt">lora_target_linear</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">gradient_accumulation_steps</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="nt">gradient_checkpointing</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</code></pre></div>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="colab-notebook">Colab Notebook</h2>
<p>👉 <a href="https://colab.research.google.com/drive/1Uau3HzU3tVnhfeAK1fVpypbKoTrETDNK?usp=sharing">Open in Colab</a><br />
<a href="https://colab.research.google.com/drive/1Uau3HzU3tVnhfeAK1fVpypbKoTrETDNK?usp=sharing"><img alt="Open in Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="references-further-reading_2">References &amp; Further Reading</h2>
<ul>
<li><a href="https://github.com/deepspeedai/DeepSpeed">DeepSpeed GitHub</a></li>
<li><a href="https://github.com/axolotl-ai-cloud/axolotl/tree/main/deepspeed_configs">Axolotl DeepSpeed Configs</a></li>
<li><a href="https://huggingface.co/docs/accelerate/en/usage_guides/deepspeed">Hugging Face DeepSpeed Guide</a></li>
<li><a href="https://arxiv.org/abs/1910.02054">ZeRO Optimizer Paper</a></li>
<li><a href="https://github.com/OpenAccess-AI-Collective/axolotl">Axolotl Project</a></li>
<li><a href="https://huggingface.co/datasets/squad">SQuAD Dataset – Hugging Face</a></li>
</ul>
<p><a href="#quick-navigation">Back to Top</a></p>
<h2 id="fully-sharded-data-parallel-fsdp-theoretical-insights">Fully Sharded Data Parallel (FSDP) Theoretical Insights</h2>
<h2 id="quick-navigation_4">📌 Quick Navigation</h2>
<ul>
<li><a href="#1-overview-of-fsdp">## 1. Overview of FSDP</a></li>
<li><a href="#2-why-fsdp-over-ddp">## 2. Why FSDP Over DDP?</a></li>
<li><a href="#3-sharding-strategies-in-fsdp">## 3. Sharding Strategies in FSDP</a></li>
<li><a href="#4-model-comparison-fsdp-vs-zero">## 4. Model Comparison: FSDP vs ZeRO</a></li>
<li><a href="#5-when-to-use-fsdp">## 5. When to Use FSDP</a></li>
<li><a href="#references--further-reading">## References &amp; Further Reading</a></li>
</ul>
<hr />
<h2 id="1-overview-of-fsdp">1. Overview of FSDP</h2>
<p><strong>FSDP (Fully Sharded Data Parallel)</strong> is a PyTorch-native distributed training framework developed by Meta AI. It's designed for <strong>efficient memory usage and scalability</strong> while training large models—especially LLMs.</p>
<ul>
<li>Origin: Introduced by Meta within the PyTorch ecosystem.</li>
<li>Key Use: Enables models too large for single GPU memory.</li>
<li>Core Idea: Shard model weights, gradients, and optimizer states across multiple GPUs.</li>
</ul>
<p>🧩 <strong>Main Capabilities:</strong></p>
<ul>
<li>Memory-efficient training via model sharding.</li>
<li>Smart offloading of model shards between GPU and CPU.</li>
<li>Compatible with massive models (GPT-like, BERT variants).</li>
<li>Reduces per-GPU memory footprint → supports larger batch sizes.</li>
</ul>
<p><a href="#-quick-navigation">Back to Top</a></p>
<hr />
<h2 id="2-why-fsdp-over-ddp">2. Why FSDP Over DDP?</h2>
<table>
<thead>
<tr>
<th>Technique</th>
<th>Replicates Model</th>
<th>Memory Pooling</th>
<th>Model Size Suitability</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td>DDP (Distributed Data Parallel)</td>
<td>✅ Full model replicated</td>
<td>❌ No memory pooling</td>
<td>Medium</td>
<td>Speed-focused training</td>
</tr>
<tr>
<td>FSDP</td>
<td>❌ Fully sharded</td>
<td>✅ Memory-efficient</td>
<td>Large-scale</td>
<td>Training LLMs beyond single GPU</td>
</tr>
</tbody>
</table>
<p>🔍 Unlike DDP, FSDP:
- Does <strong>not</strong> replicate the full model.
- <strong>Shards</strong> weights across GPUs.
- Optimizes <strong>both training speed and memory usage</strong>.</p>
<p><a href="#-quick-navigation">Back to Top</a></p>
<hr />
<h2 id="3-sharding-strategies-in-fsdp">3. Sharding Strategies in FSDP</h2>
<p>FSDP provides 4 sharding strategies, similar in spirit to ZeRO stages (used by DeepSpeed):</p>
<h3 id="no-sharding">🔵 No Sharding</h3>
<ul>
<li>Equivalent to DDP.</li>
<li>No memory savings.</li>
<li>Fastest strategy (lowest overhead).</li>
<li>Use if memory isn’t a bottleneck.</li>
</ul>
<h3 id="gradients-optimizer-sharding-similar-to-zero-stage-2">🟡 Gradients &amp; Optimizer Sharding (Similar to ZeRO Stage 2)</h3>
<ul>
<li>Gradients and optimizer states are sharded.</li>
<li>Parameters still replicated.</li>
<li>Balanced trade-off between speed and memory.</li>
</ul>
<h3 id="hybrid-sharding">🟢 Hybrid Sharding</h3>
<ul>
<li>Shards parameters + optimizer states.</li>
<li>Maintains full copy of model on each GPU for fast inference.</li>
<li>Best for scenarios with frequent inference and evaluation needs.</li>
</ul>
<h3 id="full-sharding-similar-to-zero-stage-3">🔴 Full Sharding (Similar to ZeRO Stage 3)</h3>
<ul>
<li>Shards everything: parameters, gradients, optimizer states.</li>
<li>Best memory efficiency.</li>
<li>Ideal for very large models.</li>
<li>Adds communication overhead → may slow down training.</li>
</ul>
<p>📊 <strong>Sharding Strategy Comparison Table:</strong></p>
<table>
<thead>
<tr>
<th>Strategy</th>
<th>Parameters</th>
<th>Gradients</th>
<th>Optimizer</th>
<th>Memory Efficient</th>
<th>Fast Inference</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td>No Shard</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>🔴</td>
<td>🟢</td>
<td>Small models</td>
</tr>
<tr>
<td>Grad+Opt</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
<td>🟡</td>
<td>🟡</td>
<td>Balanced setup</td>
</tr>
<tr>
<td>Hybrid</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>🟢</td>
<td>🟢</td>
<td>Training + eval</td>
</tr>
<tr>
<td>Full</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>🟢🟢🟢</td>
<td>🔴</td>
<td>Huge models</td>
</tr>
</tbody>
</table>
<p><a href="#-quick-navigation">Back to Top</a></p>
<hr />
<h2 id="4-model-comparison-fsdp-vs-zero">4. Model Comparison: FSDP vs ZeRO</h2>
<table>
<thead>
<tr>
<th>Feature</th>
<th>FSDP</th>
<th>ZeRO (DeepSpeed)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Native to</td>
<td>PyTorch</td>
<td>DeepSpeed/ONNX</td>
</tr>
<tr>
<td>Sharding Levels</td>
<td>Full</td>
<td>Stage 1 to 3</td>
</tr>
<tr>
<td>CPU Offloading</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Model-Agnostic</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Hardware Compatibility</td>
<td>Any PyTorch GPU setup</td>
<td>Azure/AWS optimized</td>
</tr>
<tr>
<td>Supported Community</td>
<td>Meta AI</td>
<td>Microsoft</td>
</tr>
</tbody>
</table>
<p>🔎 FSDP has tighter PyTorch integration, making it easier for native PyTorch workflows.</p>
<p>📎 <a href="https://huggingface.co/docs/accelerate/usage_guides/fsdp">FSDP on Hugging Face</a>
📄 <a href="https://arxiv.org/abs/2210.06628">FSDP ArXiv Paper</a></p>
<p><a href="#-quick-navigation">Back to Top</a></p>
<hr />
<h2 id="5-when-to-use-fsdp">5. When to Use FSDP</h2>
<p>🏁 <strong>Best suited when:</strong></p>
<ul>
<li>You're training models with billions of parameters.</li>
<li>GPU memory is insufficient for full-model replication.</li>
<li>You need to scale across 4+ GPUs with low memory usage.</li>
<li>You want fine-grained control over training memory behavior.</li>
</ul>
<p>🚩 <strong>Not necessary when:</strong></p>
<ul>
<li>Models fit easily on a single GPU.</li>
<li>Training speed is more important than memory savings.</li>
</ul>
<p>🧠 Bonus: Even without full sharding, FSDP helps reduce memory usage to allow <strong>larger batch sizes</strong>.</p>
<p><a href="#-quick-navigation">Back to Top</a></p>
<hr />
<h2 id="references-further-reading_3">References &amp; Further Reading</h2>
<ul>
<li>
<p><a href="https://arxiv.org/abs/2210.06628">📄 FSDP: Fully Sharded Data Parallel Training (ArXiv)</a><br />
  The original research paper introducing FSDP, explaining its architecture, design rationale, and performance benchmarks.</p>
</li>
<li>
<p><a href="https://huggingface.co/docs/accelerate/usage_guides/fsdp">🧪 Hugging Face Accelerate: FSDP Training Guide</a><br />
  Practical guidance on using FSDP with Hugging Face's Accelerate library for distributed training.</p>
</li>
<li>
<p><a href="https://pytorch.org/tutorials/intermediate/FSDP_tutorial.html">📘 PyTorch FSDP Tutorial (Official)</a><br />
  Step-by-step code tutorial from the PyTorch team demonstrating how to use <code>torch.distributed.fsdp</code>.</p>
</li>
<li>
<p><a href="https://engineering.fb.com">💬 Meta AI Engineering Blog</a><br />
  Technical blog posts by Meta on distributed training innovations, including the development of FSDP.</p>
</li>
<li>
<p><a href="https://github.com/NVIDIA/Megatron-LM">🧠 NVIDIA Megatron-LM</a><br />
  One of the earliest large-scale model training toolkits that inspired advances in sharded training techniques.</p>
</li>
<li>
<p><a href="https://www.deepspeed.ai/tutorials/zero/">💻 DeepSpeed ZeRO Documentation (Microsoft)</a><br />
  Deep dive into ZeRO stages 1–3, which parallel FSDP's sharding strategies in philosophy and effect.</p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=FZs7-vP3L3I">🎥 YouTube – Scaling Transformers with FSDP (Meta AI)</a><br />
  Video walkthrough of how FSDP works and how it's applied in production-scale transformer training.</p>
</li>
<li>
<p><a href="https://arxiv.org/abs/1910.02054">📚 Microsoft ZeRO-3 Optimization Paper</a><br />
  Foundational paper on memory-optimized training with ZeRO, useful for comparing against FSDP.</p>
</li>
</ul>
<p><a href="#-quick-navigation">Back to Top</a></p>
<hr />
<h2 id="applying-fsdp-in-practice">Applying FSDP in Practice</h2>
<p>--</p>
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<h2 id="course-conclusion-and-future-directions">Course Conclusion and Future Directions</h2>
<hr />
<p><a href="#quick-navigation">Back to Top</a></p>
<hr />
<p>⬅️ <strong>Previous:</strong> <a href="11-llm-specialized.html">Specialized LLM Training</a>  </p>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="July 28, 2025 17:57:37 UTC">July 28, 2025</span>
  </span>

    
    
    
    
  </aside>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/baskarm/generative-ai-study-hub" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "navigation.indexes", "navigation.instant", "navigation.tracking", "navigation.footer", "content.footer", "toc.integrate", "search.suggest", "search.highlight", "content.code.annotate", "content.tabs.link", "content.action.edit"], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.56ea9cef.min.js"></script>
      
        <script src="/generative-ai-study-hub/service-worker.js"></script>
      
    
  </body>
</html>